{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader , DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML'S Loaded\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"D:\\Anurag-Agri-Bot\\templates/\"\n",
    "dir_loader = DirectoryLoader(\n",
    "    data_path,\n",
    "    glob='*.html',\n",
    "    loader_cls=UnstructuredHTMLLoader\n",
    ")\n",
    "docs = dir_loader.load()\n",
    "print(\"HTML'S Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Chunks Created\n"
     ]
    }
   ],
   "source": [
    "txt_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 200\n",
    ")\n",
    "inp_txt = txt_splitter.split_documents(docs)\n",
    "print(\"Data Chunks Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "d:\\project\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "d:\\project\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Created\n"
     ]
    }
   ],
   "source": [
    "hfembeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"thenlper/gte-large\",\n",
    "    model_kwargs = {'device':'cuda'}\n",
    ")\n",
    "print(\"Embedding Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store Creation Completed and Stored Locally\n"
     ]
    }
   ],
   "source": [
    "db = FAISS.from_documents(inp_txt,hfembeddings)\n",
    "db.save_local(r\"D:\\Anurag-Agri-Bot\\datas\\faiss\\custum_website\")\n",
    "print(\"Vector Store Creation Completed and Stored Locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import CTransformers , HuggingFaceHub\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = '''\n",
    "With the information provided try to answer the question. \n",
    "If you cant answer the question based on the information either say you cant find an answer or unable to find an answer.\n",
    "So try to understand in depth about the context and answer only based on the information provided. Dont generate irrelevant answers\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Do provide only helpful answers\n",
    "\n",
    "Helpful answer:\n",
    "'''\n",
    "INP_VARS = ['context', 'question']\n",
    "custom_prompt_template = PromptTemplate(\n",
    "    template = PROMPT_TEMPLATE,\n",
    "    input_variables = INP_VARS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(\n",
    "    model = r\"D:\\Anurag-Agri-Bot\\llms\\llama-2-7b-chat.ggmlv3.q4_1.bin\",\n",
    "    model_type=\"llama\",\n",
    "    max_new_tokens = 1024,\n",
    "    temperature = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Created\n"
     ]
    }
   ],
   "source": [
    "hfembeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"thenlper/gte-large\",\n",
    "    model_kwargs = {'device':'cpu'}\n",
    ")\n",
    "print(\"Embedding Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = FAISS.load_local(r\"D:\\Anurag-Agri-Bot\\datas\\faiss\\custum_website/\", hfembeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa_chain = RetrievalQA.from_chain_type(\n",
    "                                llm=llm,\n",
    "                                chain_type=\"stuff\",\n",
    "                                retriever=vector_db.as_retriever(search_kwargs={'k': 1}),\n",
    "                                return_source_documents=True,\n",
    "                                chain_type_kwargs={\"prompt\": custom_prompt_template}\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insurance is a contract where the insurer agrees to pay out a certain amount of money in the event of a loss. Available types of specialty insurance include:\n",
      "\n",
      "* Professional Liability Insurance\n",
      "* Cyber Liability Insurance\n",
      "* Directors and Officers Liability Insurance\n",
      "* Errors and Omissions Liability Insurance\n",
      "* Workers' Compensation Insurance\n",
      "* Commercial Auto Insurance\n",
      "* Business Interruption Insurance\n",
      "* Umbrella Insurance\n"
     ]
    }
   ],
   "source": [
    "user_input = \"what is insurances and list its availabe types ? \"\n",
    "prompt = {'query': user_input}\n",
    "model_out = retrieval_qa_chain(prompt)\n",
    "answer = model_out['result']\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
